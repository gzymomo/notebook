- [50亿数据轻松同步，业务一致性核对平台架构设计实践 - 架构 - dbaplus社群：围绕Data、Blockchain、AiOps的企业级专业社群。技术大咖、原创干货，每天精品原创文章推送，每周线上技术分享，每月线下技术沙龙。](https://dbaplus.cn/news-141-4876-1.html)

**50亿数据同步经验分享**

**1、背景**

 业务平台A需要在支付时，查询财务凭证数据，而这些凭证数据保存在系统B中。凭证数据情况如下:

 存量超过50亿（两表关联后），需要拉取字段约70个；

 日增（新增/更新）量500w-1500w；

 使用oracle存储。

 **2、同步方案**

 **1）整体步骤**

 先做全量迁移，记录起始时间T1和结束时间T2。

 等全量迁移完成后，再做增量迁移，增量时间起点是T1。

 进行数据核对。

 **2）全量同步任务切分**

- 以业务日期（yyyyMMdd）字段budat作为切分条件，先以年为界限分成2005-2021共计7个任务{job1,job2,job3,job4,job5,job6,job7}，不同job并发执行。

 每个job再以“天”为切分条件，分成356个实例task{task1,task2,...,task365}，task串行执行。

 **3）增量同步任务**

 使用更新时间update_time作为查询条件，配置定时10分钟调度任务，每次同步范围是update_time between t-15 and t-5，t的初始值是T1。

 当一个调度时间nextScheduleTime > now()的时间，[T1,now()]内的增量数据已经全部同步完毕！

 **4）数据一致性检查任务**

 和全量任务相似，用budat作为条件每次核对1天数据，直到下一个调度时间大于当前时间则停止。

 增量核对任务改成每天核对T-1的增量数据。

 **3、经验总结**

-  **分治**

 找到能使数据拆分（相对）均衡的字段，以该字段为核心继续细分数据直到单次任务的耗时可接受。

 如果倾斜严重，可以多选择几个字段或者改成where k=xx and hash(k)%N = n

- **顺序**

 先全量，再增量。因为历史数据是可能被修改的，如果刚好全量同步任务和增量任务对查询到同一条记录的不同版本，可能会出写入冲突或者旧版本数据覆盖性版本数据等情况

 **增量范围**

 增量任务的起始时间一般要比全量任务早几分钟

 增量任务的截止时间小于当前时间，避免由于上游（一般拉从库）主从延迟过高导致数据丢失