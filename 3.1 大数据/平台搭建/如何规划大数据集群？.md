- [如何规划大数据集群？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/353602060)

## **01 如何做大数据集群规划设计**

通常，对于给定业务的大数据集群来说，应该如何规划集群才能使硬件资源不浪费？由于成本考量只有少量节点的情况下如何规划集群的主节点和从节点才合理？对于集群的副本数如何设置才比较合适？给定容量的集群到底能存储多少数据？等等，想必这些问题也应该曾经或者目前正在困惑着很多的大数据技术人员或者运维人员，本文将结合笔者在实际工作中的经验简单的对这些问题解析和分享，希望对读者能够有一定的帮助。下面笔者以构建Hadoop和HBase分布式文件系统来说明如何规划集群。

## 02 从集群性能和运维角度考虑

- **单机配置性能**

在进行集群规划时，对于单机机器资源配置主要是从内存、CPU、硬盘、网络等方面进行考虑。通常情况下大数据集群中分为两类节点：主节点和从节点，比如Hadoop中的NameNode就是主节点，而DataNode就是从节点。下面具体说明各种资源在选择时应该考虑哪些关键因素。

对于内存的考量，通常选择比较大的内存节点。**如果是主节点通常情况下对内存的要求更高，需要配置更大的内存，而从节点就没必要像主节点那么大，可能更关注的是磁盘和CPU指标了。**对于小微集群，通常所有的节点可能配置都是一样的，所以可根据实际情形进行选择。

对于CPU的考量，不同的节点可以根据要求而不同的，**比如对于主节点可以选择2路32核或者更高性能的CPU，而从节点可以适当降低一些要求，选择2路16核的CPU。**如果集群规模比较小，所有的节点配置完全相同。

对于磁盘的考量，通常情况下会按照集群的总体规模进行规划。**对于从节点来说，安装的都是数据存储节点或者计算节点，往往都选择比较大的磁盘，比如由多块2T或者4T组成的20T或40T的磁盘。**而对于主节点来说，通常安装的都是主节点需要的是内存，对磁盘的要求比较低，不过**如果同时也安装了从节点磁盘也需要配置比较大的磁盘。**但有一点，**为了保证负载均衡和集群性能，所有从节点的磁盘空间配置要尽量保持一致。**

对于网络的考量，通常对于大数据平台往往数据量都是非常巨大的，网络的吞吐率要求也比较高，所以在条件允许的情况下都选择万兆网。

- **应用分布规划**

从集群的系统性能方面考虑，希望集群的整体性能尽可能比较高，资源使用率尽可能大，而从运营维护角度考虑，当集群某个节点出现故障时希望对集群的可用性、稳定性等方面的影响尽可能小，下面我们以通常情况下按照如下分配所有的应用程序。

对于小微集群来说，集群节点个数往往比较少（有时可能只有几台服务器），这样多个节点需要进行共享。如果集群的节点个数少于5个，我们以4个节点的集群、HA模式为例，可以按照如下进行应用分布设计：

Node01: NN、RM、HM

Node02: NN、RM、HM、JN、ZK

Node03: DN、NM、RS、JN、ZK

Node04: DN、NM、RS、JN、ZK

对于如上的集群配置，这样的集群抗风险和容错能力比较差，集群的扩展能力也方便，当有节点发生故障需要机器下线操作起来也不方便，所以仅适合于做开发环境或者实时性要求比较低的批处理集群。

对于节点数大于等于5个节点时，集群就可以按照如下进行分布设计：

Node01: NN、RM、HM

Node02: NN、RM、HM

Node03: JN、ZK、DN、NM、RS

Node04: JN、ZK、DN、NM、RS

Node05: JN、ZK、DN、NM、RS

Node06: DN、NM、RS

Node07: DN、NM、RS

......

NodeNN: DN、NM、RS

对于这样的集群随着业务规模的扩展，我们随时可以很方便的将Node03、Node04、Node05上的DN、NM、RS都下线，使集群的分布变更为：

Node01: NN、RM、HM

Node02: NN、RM、HM

Node03: JN、ZK

Node04: JN、ZK

Node05: JN、ZK

Node06: DN、NM、RS

Node07: DN、NM、RS

......

NodeNN: DN、NM、RS

上述中的简写名称分别代表：NN代表NameNode，RM代表ResourceManager，HM代表HMaster，DN代表DataNode，JN代表JournalNode，ZK代表Zookeeper，NM代表NodeManager，RS代表RegionServer。

## 03 从存储容量角度规划考虑

在进行集群规划时同时还需要从存储容量角度考虑，可以按照如下四个方面进行规划：

- **数据范围**

在实际业务中，对于任何一个企业其业务条线都会有其自己的业务增长趋势，这样随着业务规模的增长企业数据量也会不断增长，所以我们在规划集群时可以按照短期业务（1～2年）、中长期（3～5年）业务增长进行规划，而不是在集群初始化时一次性导入的初始数据量。

比如：我们假设企业的客户量x，所有客户产生的所有业务数据量为y，在构建集群时的初始数据量为c，那么可能的一种企业数据量增长模型为

y = a*f(x) + b*g(x) + c

其中，在大部分企业中如果客户量增加一个量级dx，那么其所对应的日志和订单业务数据量可能是客户量的线性模型f(x)，而对于交易类业务的数据量可能是客户量的非线性增长模型g(x)，比如笛卡尔积模型。

所以不能通过简单的节点动态增加来调整集群规模和存储计算能力，最好还是通过构建短期业务和中长期业务增长趋势模型来规划集群。

- **数据分级**

在现实企业中，对于不同业务条线的数据具有不同的安全等级，比如对于金融企业交易数据具有较高的安全等级，对于电商企业订单数据可能具有较高的安全等级。同时廉价的商用服务器出现故障也更容易，这样可以通过多副本策略进行存储，保障数据的安全。所以在实际业务中我们可以按照业务数据的安全等级进行数据分级划分，这样在进行数据存储时高安全等级数据可以存储更多副本的数据，而低安全等级数据可以少存储一些副本，这样就可以根据数据的安全等级划分，一来保障数据的安全，二来可以节约大量的存储空间。

- **数据格式**

数据格式也是会影响存储空间和性能的一个考量指标。对于实际的企业数据，通常会有JSon、CSV、Parquet、ORC、DAT等格式的数据，我们以实际使用中对Json、Csv、Parquet三种类型的业务数据进行分析测试，得出如下的结论：

1）对于相同的数据集使用三种格式进行存储，对空间的使用比例接近2:1:0.3左右；

2）我们以一个2亿条记录的二维表、HDFS文件系统中3个副本结构为例，如果使用Json格式存储该数据集会占用200G空间，那么使用Csv格式存储大约会占用100G空间，而使用Parquet格式存储大约会占用30G空间；

3）其中的Parquet格式占用会有部分偏差，因为Parquet底层使用的数据压缩算法，对于不同数据分布列会有不同的压缩比，比如对于均匀分布列、枚举值列、长尾分布列等压缩比例会有不同，但对于实际的业务数据，总体上Parquet的压缩还是比较不错的。

所以在对集群进行使用时建议尽量使用Parquet等这类压缩性能比较高的格式进行存储，这样会节省大量的空间。

- **数据功能**

对于集群中产生的数据可以按照业务中间数据、临时数据、集群的系统日志、集群的预留空间安全系数等来进行规划。业务中间数据和临时数据会分配一定的空间比例，对于集群的预留空间安全系数可以按照当集群的总体规模使用达到80%就需要进行横向扩容，等等。

笔者曾经在实践中遇到过如下情形，原始的业务数据大概有15T左右，通过多副本存储策略、数据处理过程中产生的大量中间和临时数据、再加上集群需要有预留空间的安全系数等，当时整个集群120T的总空间尽然都不够用，也就是说现实中的业务数据在使用中总体上可能会膨胀好多倍。